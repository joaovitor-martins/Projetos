# -*- coding: utf-8 -*-
"""RecomedaçãoFilme.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18-sGTYp5M3DpgWEtJS6fWN5whra_JS0o

## Instalando e Carregando os Pacotes
"""

# Imports
import ast
import nltk
import sklearn
import numpy as np
import pandas as pd
from nltk.stem.porter import PorterStemmer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity
pd.options.mode.chained_assignment = None

"""## Carregando os Dados"""

# Dataset de filmes
df_filmes = pd.read_csv("/content/dataset_filmes.csv")

df_filmes.shape

df_filmes.head(3)

# Dataset de elenco dos filmes
df_elenco = pd.read_csv("/content/dataset_elenco.csv")

df_elenco.shape

df_elenco.head(3)

# Estamos unindo os 2 datasets, usando a coluna comum entre eles o TITULO do filme, por meio do MERGE
df_filmes = df_filmes.merge(df_elenco, on = 'title')

df_filmes.shape

df_filmes.head(3)

df_filmes.info()

# Selecionando as colunas que são mais provaveis de serem relevantes
df_filmes = df_filmes[['movie_id', 'title', 'overview', 'genres', 'keywords', 'cast', 'crew']]

df_filmes.head(3)

"""## Análise Exploratória e Limpeza dos Dados"""

# Vendo os valores ausentes
df_filmes.isnull().sum()

# Removemos as linhas com valores ausentes
df_filmes.dropna(inplace = True)

# Checando se ainda tem ausentes
df_filmes.isnull().sum()

# Vendo valores duplicados
df_filmes.duplicated().sum()

# Vendo um exemplo da coluna CREW(Equipe de apoio)
df_filmes['crew'].iloc[0]

"""## Processamento de Texto com Abstract Syntax Trees"""

df_filmes.head(3)

#  Avaliamos um exemplo, e notamos que eles podem possuir varios valores no formato chave-valor
ast.literal_eval('[{"id": 28, "name": "Action"}, {"id": 12, "name": "Adventure"}, {"id": 14, "name": "Fantasy"}, {"id": 878, "name": "Science Fiction"}]')

# Função de conversão
# Analisa a lista(campo) e procura a palavra relacionada ao NAME, e adiciona a lista vazia
def converter(obj):
    L = []
    for i in ast.literal_eval(obj):
        L.append(i['name'])
    return L

# Vamos testar a função
teste = converter('[{"id": 28, "name": "Action"}, {"id": 12, "name": "Adventure"}, {"id": 14, "name": "Fantasy"}, {"id": 878, "name": "Science Fiction"}]')

# Agora a lista possui apenas o nome do genero, sem ID e nome dos campos
print(teste)

# Aplicando em todas as colunas de genero no dataset
df_filmes['genres'] = df_filmes['genres'].apply(converter)

df_filmes.head()

# Notamos que a coluna KEYWORDS, se comporta no mesmo formato que a GENRES, então aplicamos a mesma função CONVERTER
df_filmes['keywords'] = df_filmes['keywords'].apply(converter)

df_filmes.head()

# Em relação ao elenco, vamos ultilizar a função CONVERTER tambem(mesmo estilo), porem iremos pedir para que retorne os 3º artistas(podemos variar)
# Função de conversão3
def converter3(obj):
    L = []
    counter = 0
    for i in ast.literal_eval(obj):
        if counter != 3:
            L.append(i['name'])
            counter += 1
        else:
            break
    return L

# Aplicando a função no dataset
df_filmes['cast'] = df_filmes['cast'].apply(converter3)

df_filmes.head()

# Agora, iremos usar a função CONVERTER na coluna CREW, porem vamos colocar um IF para ele retornar apenas o diretor do filme, ou seja irar analisa o campo,
# buscar a palavra DIRECTOR e trazer o valor correspondente(Chave-valor)
# Função de conversão
def fetch_director(obj):
    L = []
    for i in ast.literal_eval(obj):
        if i['job']=='Director':
            L.append(i['name'])
            break
    return L

# Aplicando em todo dataset
df_filmes['crew'] = df_filmes['crew'].apply(fetch_director)

df_filmes.head()

"""## Limpeza dos Dados de Texto"""

# Separando cada palavra da sinopse do filme como se fosse um vetor unico, quando aparecer um espaçõ virar um novo vetor
df_filmes['overview'] = df_filmes['overview'].apply(lambda x:x.split())

df_filmes.head()

# Tornando os valores de Genere em campos unicos, caso seja uma palavra composta(Ex: Science Fiction)(RETIRAR O ESPAÇO)
df_filmes['genres'] = df_filmes['genres'].apply(lambda x:[i.replace(" ","") for i in x])

# A mesma ideia só que para as KEYWORDS
df_filmes['keywords'] = df_filmes['keywords'].apply(lambda x:[i.replace(" ","") for i in x])

# A mesma ideia só que para o CAST
df_filmes['cast'] = df_filmes['cast'].apply(lambda x:[i.replace(" ","") for i in x])

# A mesma ideia só que para o CREW
df_filmes['crew'] = df_filmes['crew'].apply(lambda x:[i.replace(" ","") for i in x])

df_filmes.head()

"""## Preparando os Dados Para Vetorização em Outro Espaço Vetorial"""

# Unimos todos os termos de todas as colunas em 1 só(TAG), assim só precisamos rodar um comando para o vetor
df_filmes['tags'] = df_filmes['overview'] + df_filmes['genres'] + df_filmes['keywords'] + df_filmes['cast'] + df_filmes['crew']

df_filmes.head()

# Dataset final
df_filmes_novo = df_filmes[['movie_id', 'title', 'tags']]

df_filmes_novo.head()

# Join das strings para simplificar o vetor
df_filmes_novo['tags'] = df_filmes_novo['tags'].apply(lambda x:" ".join(x))

# Colocando tudo em minúsculo
df_filmes_novo['tags'] = df_filmes_novo['tags'].apply(lambda x:x.lower())

df_filmes_novo.head(10)

"""## Parse e Vetorização"""

# Criamos o parser
# Stemming é o processo de redução de uma palavra ao seu radical que está ligado a sufixos e prefixos ou às raízes de palavras conhecidas como "lemmas".
# Stemming é importante na compreensão de linguagem natural e processamento de linguagem natural.
parser_ps = PorterStemmer()

# Aplicando stemming em todas as palavras de TAGS
# Função de stemming
def stem(text):
    y = []
    for i in text.split():
        y.append(parser_ps.stem(i))
    return " ".join(y)

# Aplicando a função na coluna de tags
df_filmes_novo['tags'] = df_filmes_novo['tags'].apply(stem)

df_filmes_novo.head()

# Cria o vetorizador com no máximo 5000 atributos
# CountVetorizer - Aprende o comportamento e transofrma em vetor
# Stopword - Pronomes em ingle
cv = CountVectorizer(max_features = 5000, stop_words = 'english')

# Cria os vetores para as tags
vectors = cv.fit_transform(df_filmes_novo['tags']).toarray()

len(cv.get_feature_names_out())

type(vectors)

vectors

# Para visualizar todas as colunas do array
np.set_printoptions(threshold = np.inf)

vectors[0]

vectors[1]

"""## Cálculo de Distância dos Vetores

A célula abaixo trabalha com os vetores no espaço de dimensão para calcular a distância matemática entre eles usando a distância de cosseno (cosine_similarity).

* Se a distancia entre os vetores for pequena = Similares
* Se a distancia entre os vetores for grande = Diferentes
"""

# Calcula a similaridade entre os vetores calculando as distâncias entre eles
similaridade = cosine_similarity(vectors)

"""## Sistema de Recomendação"""

# Função para o sistema de recomendação
def sistema_recomendacao(movie):

    # Obtém o índice do filme passado como argumento (o que o usuário assistiu)
    # Usuario digitou o filme, e encontrou 2 por exemplo, usa o 1º, gerando um indice
    index = df_filmes_novo[df_filmes_novo['title'] == movie].index[0]

    # Verificamos então os filmes com vetores de menor distância para o filme passado como argumento
    # Busca o indice gerado, e busca todos filmes similares com esse indice
    distances = sorted(list(enumerate(similaridade[index])), reverse = True, key = lambda x: x[1])

    # E então consideramos os 5 filmes com menor distância, ou seja, mais similares
    for i in distances[1:6]:
        print(df_filmes_novo.iloc[i[0]].title)

# Quais as recomendações de filmes para quem assistiu ao filme Spider-Man 3?
sistema_recomendacao('Spider-Man 3')

# Quais as recomendações de filmes para quem assistiu ao filme Avatar?
sistema_recomendacao('Avatar')

# Quais as recomendações de filmes para quem assistiu ao filme Independence Day?
sistema_recomendacao('Independence Day')

# Quais as recomendações de filmes para quem assistiu ao filme Piratas do Caribe?
sistema_recomendacao("Pirates of the Caribbean: At World's End")

# Prompt para o usuario
sistema_recomendacao()