{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "03ac806f",
      "metadata": {
        "id": "03ac806f"
      },
      "source": [
        "## Instalando e Carregando os Pacotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e708efe4",
      "metadata": {
        "id": "e708efe4"
      },
      "outputs": [],
      "source": [
        "# Imports dos pacotes\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from os import getcwd\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e4c534f",
      "metadata": {
        "id": "8e4c534f"
      },
      "source": [
        "## Extra√ß√£o e Carga dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e54b355",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e54b355",
        "outputId": "7847fe99-1a3f-4280-f90c-9a033c034399"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Package twitter_samples is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ],
      "source": [
        "# Download dos dados\n",
        "nltk.download('twitter_samples')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2befdc9b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2befdc9b",
        "outputId": "20f67cf0-fb60-4fd4-ecf7-f7db61c8339b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ],
      "source": [
        "# Download das stopwords\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79cced64",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79cced64",
        "outputId": "f2000521-4de4-4f64-c0ce-9228d02516d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 116
        }
      ],
      "source": [
        "# Verifica a pasta\n",
        "getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12656e11",
      "metadata": {
        "id": "12656e11"
      },
      "outputs": [],
      "source": [
        "# Importa o Corpus (dados)\n",
        "from nltk.corpus import twitter_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0e43e76",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0e43e76",
        "outputId": "ee91d3ac-6b94-4fb0-8d83-174a325b5b20"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nltk.corpus.reader.twitter.TwitterCorpusReader"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ],
      "source": [
        "type(twitter_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f55dbe2",
      "metadata": {
        "id": "4f55dbe2"
      },
      "source": [
        "## Prepara√ß√£o dos Dados\n",
        "\n",
        "O objeto `twitter_samples` cont√©m subconjuntos de 5 mil tweets positivos, 5 mil tweets negativos e o conjunto completo de 10.000 tweets.\n",
        "\n",
        "Vamos trabalhar com as duas amostras de 5 mil tweets cada uma."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbd225fb",
      "metadata": {
        "id": "fbd225fb"
      },
      "outputs": [],
      "source": [
        "# Carregando os tweets positivos\n",
        "tweets_positivos = twitter_samples.strings('positive_tweets.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9d403cd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9d403cd",
        "outputId": "807b271c-44a6-41b2-fe61-dffb3d88f48b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ],
      "source": [
        "len(tweets_positivos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9621e64e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9621e64e",
        "outputId": "bff47bfc-65e4-4359-c220-432170478c9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@DespiteOfficial we had a listen last night :) As You Bleed is an amazing track. When are you in Scotland?!',\n",
              " '@97sides CONGRATS :)',\n",
              " 'yeaaaah yippppy!!!  my accnt verified rqst has succeed got a blue tick mark on my fb profile :) in 15 days',\n",
              " '@BhaktisBanter @PallaviRuhail This one is irresistible :)\\n#FlipkartFashionFriday http://t.co/EbZ0L2VENM',\n",
              " \"We don't like to keep our lovely customers waiting for long! We hope you enjoy! Happy Friday! - LWWF :) https://t.co/smyYriipxI\",\n",
              " '@Impatientraider On second thought, there‚Äôs just not enough time for a DD :) But new shorts entering system. Sheep must be buying.']"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ],
      "source": [
        "# Amostra de alguns tweets positivos\n",
        "tweets_positivos[2:8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fa49926",
      "metadata": {
        "id": "4fa49926"
      },
      "outputs": [],
      "source": [
        "# Carregando os tweets negativos\n",
        "tweets_negativos = twitter_samples.strings('negative_tweets.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d25baaf5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d25baaf5",
        "outputId": "f0d33521-e28c-42c0-f883-66c606c27ec3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ],
      "source": [
        "len(tweets_negativos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20236f37",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20236f37",
        "outputId": "51d4fb7d-5cbd-4515-ca17-9dc3c810631c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@Hegelbon That heart sliding into the waste basket. :(',\n",
              " '‚Äú@ketchBurning: I hate Japanese call him \"bani\" :( :(‚Äù\\n\\nMe too',\n",
              " 'Dang starting next week I have \"work\" :(',\n",
              " \"oh god, my babies' faces :( https://t.co/9fcwGvaki0\",\n",
              " '@RileyMcDonough make me smile :((',\n",
              " '@f0ggstar @stuartthull work neighbour on motors. Asked why and he said hates the updates on search :( http://t.co/XvmTUikWln']"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ],
      "source": [
        "# Amostra de alguns tweets negativos\n",
        "tweets_negativos[2:8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47d0d01a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47d0d01a",
        "outputId": "e3d2f436-b207-443a-fcd0-62cfb8b329b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positivos: <class 'list'>\n",
            "Negativos: <class 'list'>\n"
          ]
        }
      ],
      "source": [
        "print('Positivos:',type(tweets_positivos))\n",
        "print('Negativos:',type(tweets_negativos))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "956fd895",
      "metadata": {
        "id": "956fd895"
      },
      "source": [
        "## Divis√£o em Treino e Teste\n",
        "\n",
        "Vamos dividir os dados com uma propor√ß√£o 80/20 (treino/teste) garantindo a mesma propor√ß√£o de tweets positivos e negativos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7580340",
      "metadata": {
        "id": "e7580340"
      },
      "outputs": [],
      "source": [
        "# Divis√£o em treino e teste(80/20), separando 4000(80%) de tweets positivos para teste e 1000(20%) para treino\n",
        "tweets_positivos_teste = tweets_positivos[4000:]\n",
        "tweets_positivos_treino = tweets_positivos[:4000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8fd9d28",
      "metadata": {
        "id": "e8fd9d28"
      },
      "outputs": [],
      "source": [
        "# Divis√£o em treino e teste(80/20), separando 4000(80%) de tweets negativo para teste e 1000(20%) para treino\n",
        "tweets_negativos_teste = tweets_negativos[4000:]\n",
        "tweets_negativos_treino = tweets_negativos[:4000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fbd726a",
      "metadata": {
        "id": "8fbd726a"
      },
      "outputs": [],
      "source": [
        "# Unindo os dataset's de treino\n",
        "dados_treino_x = tweets_positivos_treino + tweets_negativos_treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "331b2826",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "331b2826",
        "outputId": "ccab0a57-c9d0-4f69-e6a7-e7b25e4f0bc2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8000"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ],
      "source": [
        "# 4000 + 4000 = 8000\n",
        "len(dados_treino_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c228b84",
      "metadata": {
        "id": "1c228b84"
      },
      "outputs": [],
      "source": [
        "# Unindo os dataset's de teste\n",
        "dados_teste_x = tweets_positivos_teste + tweets_negativos_teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f9b67f9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f9b67f9",
        "outputId": "f3b91e7e-dad6-4332-b95e-9839dbfd6692"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ],
      "source": [
        "# 1000 + 1000 = 2000\n",
        "len(dados_teste_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf2e2b50",
      "metadata": {
        "id": "bf2e2b50"
      },
      "outputs": [],
      "source": [
        "# Dando valor para positivos(1) e negativos(0) no dataset de treino\n",
        "y_treino = np.append(np.ones((len(tweets_positivos_treino), 1)),\n",
        "                     np.zeros((len(tweets_negativos_treino), 1)), axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c36451a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c36451a",
        "outputId": "6069627c-9145-44f2-8dc8-cd386b9d626f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ],
      "source": [
        "y_treino.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8c0a519",
      "metadata": {
        "id": "a8c0a519"
      },
      "outputs": [],
      "source": [
        "# Dando valor para positivos(1) e negativos(0) no dataset de teste\n",
        "y_teste = np.append(np.ones((len(tweets_positivos_teste), 1)),\n",
        "                    np.zeros((len(tweets_negativos_teste), 1)), axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6a75ccf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6a75ccf",
        "outputId": "2288be31-71ac-480f-f277-69d73cf86750"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ],
      "source": [
        "y_teste.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c478767c",
      "metadata": {
        "id": "c478767c"
      },
      "source": [
        "## Manipula√ß√£o de Texto e Pr√©-Processamento dos Dados\n",
        "\n",
        "Vamos criar uma fun√ß√£o para processar o texto dos posts do Twitter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bb558d4",
      "metadata": {
        "id": "3bb558d4"
      },
      "outputs": [],
      "source": [
        "# Fun√ß√£o para limpeza e processamento dos tweets\n",
        "def limpa_processa_tweet(tweet):\n",
        "\n",
        "    # Retirar as stopword(artigo, pronome, ...), em ingles por que os tweets est√£o em ingles\n",
        "    stopwords_ingles = stopwords.words('english')\n",
        "\n",
        "    # Remover o $ em caso como $GE(colado com uma palavra), e vou substituir por vazio ''\n",
        "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
        "\n",
        "    # Remover o 'RT'(colado com uma palavra), e vou substituir por vazio ''\n",
        "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "\n",
        "    # Remove hyperlinks, removendo o HTTP ou HTTPS e substituindo por ''(vazio)\n",
        "    tweet = re.sub(r'http?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
        "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
        "\n",
        "    # Remove hashtags e substituir por ''(vazio)\n",
        "    tweet = re.sub(r'#', '', tweet)\n",
        "\n",
        "    # Cria um tokenizador, para separar as frases em palavras\n",
        "    tokenizer = TweetTokenizer(preserve_case = False, strip_handles = True, reduce_len = True)\n",
        "\n",
        "    # Aplica o tokenizador\n",
        "    tweet_tokens = tokenizer.tokenize(tweet)\n",
        "\n",
        "    # Lista para os tweets limpos\n",
        "    tweets_tratados = []\n",
        "\n",
        "    # Cria o objeto Stemmer(fun√ß√£o para deixar os radicais das palavras)\n",
        "    stemmer = PorterStemmer()\n",
        "\n",
        "    # Loop para percorrer as palavras na lista dos tweets\n",
        "    for palavra in tweet_tokens:\n",
        "\n",
        "        # Removendo as stop words e pontua√ß√£o\n",
        "        if (palavra not in stopwords_ingles and palavra not in string.punctuation):\n",
        "\n",
        "            # Aplicando o STEMMER\n",
        "            radical_palavra = stemmer.stem(palavra)\n",
        "\n",
        "            # Tweets limpos\n",
        "            tweets_tratados.append(radical_palavra)\n",
        "\n",
        "    return tweets_tratados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d01ccef1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d01ccef1",
        "outputId": "16cb18d8-f526-4711-a7a0-454582fc3e48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Este √© um exemplo de um tweet positivo original: \n",
            "\n",
            " #FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n"
          ]
        }
      ],
      "source": [
        "# Tweet original\n",
        "print('Este √© um exemplo de um tweet positivo original: \\n\\n', dados_treino_x[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "082ab8da",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "082ab8da",
        "outputId": "82c7cb3a-dd04-4d8f-e8c2-1e054d57581a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Este √© um exemplo da vers√£o processada do tweet: \n",
            "\n",
            " ['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']\n"
          ]
        }
      ],
      "source": [
        "# Tweet tratado\n",
        "print('\\nEste √© um exemplo da vers√£o processada do tweet: \\n\\n', limpa_processa_tweet(dados_treino_x[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bc9a2bf",
      "metadata": {
        "id": "9bc9a2bf"
      },
      "outputs": [],
      "source": [
        "# Fun√ß√£o para criar o dicion√°rio de frequ√™ncia das palavras\n",
        "def cria_freqs(tweets, ys):\n",
        "\n",
        "    # tweets √© uma lista de tweets\n",
        "    # ys √© um array m x 1 com um label de sentimento para cada tweet (0 ou 1)\n",
        "\n",
        "    # Sqeeeze (remove uma das dimens√µes)\n",
        "    yslist = np.squeeze(ys).tolist()\n",
        "\n",
        "    # Dicion√°rio de frequ√™ncias\n",
        "    freqs = {}\n",
        "\n",
        "    # Loop para cada tweet\n",
        "    for y, tweet in zip(yslist, tweets):\n",
        "\n",
        "        # Loop para cada palavra\n",
        "        for word in limpa_processa_tweet(tweet):\n",
        "            pair = (word, y)\n",
        "            if pair in freqs:\n",
        "                freqs[pair] += 1\n",
        "            else:\n",
        "                freqs[pair] = 1\n",
        "\n",
        "    return freqs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "708f95fa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "708f95fa",
        "outputId": "4aeb49e9-7583-4e4f-f50d-1ee037b5dbfd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)',\n",
              " '@Lamb2ja Hey James! How odd :/ Please call our Contact Centre on 02392441234 and we will be able to assist you :) Many thanks!',\n",
              " '@DespiteOfficial we had a listen last night :) As You Bleed is an amazing track. When are you in Scotland?!',\n",
              " '@97sides CONGRATS :)',\n",
              " 'yeaaaah yippppy!!!  my accnt verified rqst has succeed got a blue tick mark on my fb profile :) in 15 days']"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ],
      "source": [
        "# Exemplo de tweets\n",
        "dados_treino_x[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9befcef3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9befcef3",
        "outputId": "dbd71354-97df-49b2-a741-69e78f486355"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ],
      "source": [
        "# Exemplo da categoria(positivo/negativo)\n",
        "y_treino[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0049403f",
      "metadata": {
        "id": "0049403f"
      },
      "outputs": [],
      "source": [
        "# fun√ß√£o de frequencia nos dados de treino\n",
        "freqs = cria_freqs(dados_treino_x, y_treino)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a65cfca0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a65cfca0",
        "outputId": "bb62ba52-f30a-491d-8ec3-f7790df72386"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ],
      "source": [
        "type(freqs)\n",
        "# Tipo dicionario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c08e456",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c08e456",
        "outputId": "f68e51ac-eac7-4db0-e72e-b02e21ab4a93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('long', 1.0): 27,\n",
              " ('hope', 1.0): 113,\n",
              " ('enjoy', 1.0): 57,\n",
              " ('happi', 1.0): 161,\n",
              " ('friday', 1.0): 91}"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ],
      "source": [
        "#Exemplo de valores positivos             # Nesse trecho[50 - 55]:\n",
        "dict(list(freqs.items())[50:55])          # Happi - Happy - Apareceu 161 vezes em tweets positivos\n",
        "                                          # Friday - Apareceu 91 em tweets positivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7c39c1d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7c39c1d",
        "outputId": "30ae0e69-a382-4ef6-ec99-bb89c7a8d094"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('ticket', 0.0): 9,\n",
              " ('codi', 0.0): 1,\n",
              " ('simpson', 0.0): 1,\n",
              " ('concert', 0.0): 9,\n",
              " ('singapor', 0.0): 3}"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ],
      "source": [
        "# Exemplo de valores negativos            # Nesse trecho[6995 - 7000]:\n",
        "dict(list(freqs.items())[6995:7000])      # Simpson - Apareceu 1 vez em tweets negativos\n",
        "                                          # Concert - Apareceu 9 vezes em tweets negativos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f004638b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f004638b",
        "outputId": "3bc5fad8-5385-4f4a-ef73-318f4642d3de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('followfriday', 1.0): 23,\n",
              " ('top', 1.0): 30,\n",
              " ('engag', 1.0): 7,\n",
              " ('member', 1.0): 14,\n",
              " ('commun', 1.0): 27,\n",
              " ('week', 1.0): 72,\n",
              " (':)', 1.0): 2847,\n",
              " ('hey', 1.0): 60,\n",
              " ('jame', 1.0): 7,\n",
              " ('odd', 1.0): 2,\n",
              " (':/', 1.0): 5,\n",
              " ('pleas', 1.0): 80,\n",
              " ('call', 1.0): 27,\n",
              " ('contact', 1.0): 4,\n",
              " ('centr', 1.0): 1,\n",
              " ('02392441234', 1.0): 1,\n",
              " ('abl', 1.0): 6,\n",
              " ('assist', 1.0): 1,\n",
              " ('mani', 1.0): 28,\n",
              " ('thank', 1.0): 504,\n",
              " ('listen', 1.0): 14,\n",
              " ('last', 1.0): 39,\n",
              " ('night', 1.0): 55,\n",
              " ('bleed', 1.0): 2,\n",
              " ('amaz', 1.0): 41,\n",
              " ('track', 1.0): 5,\n",
              " ('scotland', 1.0): 2,\n",
              " ('congrat', 1.0): 15,\n",
              " ('yeaaah', 1.0): 1,\n",
              " ('yipppi', 1.0): 1,\n",
              " ('accnt', 1.0): 2,\n",
              " ('verifi', 1.0): 2,\n",
              " ('rqst', 1.0): 1,\n",
              " ('succeed', 1.0): 1,\n",
              " ('got', 1.0): 57,\n",
              " ('blue', 1.0): 8,\n",
              " ('tick', 1.0): 1,\n",
              " ('mark', 1.0): 1,\n",
              " ('fb', 1.0): 4,\n",
              " ('profil', 1.0): 2,\n",
              " ('15', 1.0): 4,\n",
              " ('day', 1.0): 187,\n",
              " ('one', 1.0): 90,\n",
              " ('irresist', 1.0): 2,\n",
              " ('flipkartfashionfriday', 1.0): 16,\n",
              " ('like', 1.0): 187,\n",
              " ('keep', 1.0): 55,\n",
              " ('love', 1.0): 336,\n",
              " ('custom', 1.0): 4,\n",
              " ('wait', 1.0): 55,\n",
              " ('long', 1.0): 27,\n",
              " ('hope', 1.0): 113,\n",
              " ('enjoy', 1.0): 57,\n",
              " ('happi', 1.0): 161,\n",
              " ('friday', 1.0): 91,\n",
              " ('lwwf', 1.0): 1,\n",
              " ('second', 1.0): 8,\n",
              " ('thought', 1.0): 21,\n",
              " ('‚Äô', 1.0): 17,\n",
              " ('enough', 1.0): 16,\n",
              " ('time', 1.0): 100,\n",
              " ('dd', 1.0): 1,\n",
              " ('new', 1.0): 111,\n",
              " ('short', 1.0): 6,\n",
              " ('enter', 1.0): 9,\n",
              " ('system', 1.0): 2,\n",
              " ('sheep', 1.0): 1,\n",
              " ('must', 1.0): 14,\n",
              " ('buy', 1.0): 9,\n",
              " ('jgh', 1.0): 4,\n",
              " ('go', 1.0): 120,\n",
              " ('bayan', 1.0): 1,\n",
              " (':d', 1.0): 498,\n",
              " ('bye', 1.0): 5,\n",
              " ('act', 1.0): 6,\n",
              " ('mischiev', 1.0): 1,\n",
              " ('etl', 1.0): 1,\n",
              " ('layer', 1.0): 1,\n",
              " ('in-hous', 1.0): 1,\n",
              " ('wareh', 1.0): 1,\n",
              " ('app', 1.0): 12,\n",
              " ('katamari', 1.0): 1,\n",
              " ('well', 1.0): 66,\n",
              " ('‚Ä¶', 1.0): 31,\n",
              " ('name', 1.0): 12,\n",
              " ('impli', 1.0): 1,\n",
              " (':p', 1.0): 104,\n",
              " ('influenc', 1.0): 16,\n",
              " ('big', 1.0): 27,\n",
              " ('...', 1.0): 227,\n",
              " ('juici', 1.0): 3,\n",
              " ('selfi', 1.0): 11,\n",
              " ('follow', 1.0): 319,\n",
              " ('perfect', 1.0): 17,\n",
              " ('alreadi', 1.0): 19,\n",
              " ('know', 1.0): 120,\n",
              " (\"what'\", 1.0): 14,\n",
              " ('great', 1.0): 134,\n",
              " ('opportun', 1.0): 17,\n",
              " ('junior', 1.0): 2,\n",
              " ('triathlet', 1.0): 1,\n",
              " ('age', 1.0): 2,\n",
              " ('12', 1.0): 5,\n",
              " ('13', 1.0): 5,\n",
              " ('gatorad', 1.0): 1,\n",
              " ('seri', 1.0): 4,\n",
              " ('get', 1.0): 164,\n",
              " ('entri', 1.0): 3,\n",
              " ('lay', 1.0): 3,\n",
              " ('greet', 1.0): 4,\n",
              " ('card', 1.0): 6,\n",
              " ('rang', 1.0): 2,\n",
              " ('print', 1.0): 3,\n",
              " ('today', 1.0): 86,\n",
              " ('job', 1.0): 34,\n",
              " (':-)', 1.0): 543,\n",
              " (\"friend'\", 1.0): 3,\n",
              " ('lunch', 1.0): 3,\n",
              " ('yummm', 1.0): 1,\n",
              " ('nostalgia', 1.0): 1,\n",
              " ('tb', 1.0): 1,\n",
              " ('ku', 1.0): 1,\n",
              " ('id', 1.0): 8,\n",
              " ('conflict', 1.0): 1,\n",
              " ('help', 1.0): 37,\n",
              " (\"here'\", 1.0): 20,\n",
              " ('screenshot', 1.0): 2,\n",
              " ('work', 1.0): 88,\n",
              " ('hi', 1.0): 154,\n",
              " ('liv', 1.0): 2,\n",
              " ('hello', 1.0): 49,\n",
              " ('need', 1.0): 62,\n",
              " ('someth', 1.0): 25,\n",
              " ('u', 1.0): 136,\n",
              " ('fm', 1.0): 2,\n",
              " ('twitter', 1.0): 25,\n",
              " ('‚Äî', 1.0): 22,\n",
              " ('sure', 1.0): 37,\n",
              " ('thing', 1.0): 48,\n",
              " ('dm', 1.0): 34,\n",
              " ('x', 1.0): 50,\n",
              " (\"i'v\", 1.0): 25,\n",
              " ('heard', 1.0): 9,\n",
              " ('four', 1.0): 5,\n",
              " ('season', 1.0): 5,\n",
              " ('pretti', 1.0): 17,\n",
              " ('dope', 1.0): 2,\n",
              " ('penthous', 1.0): 1,\n",
              " ('obv', 1.0): 1,\n",
              " ('gobigorgohom', 1.0): 1,\n",
              " ('fun', 1.0): 45,\n",
              " (\"y'all\", 1.0): 3,\n",
              " ('yeah', 1.0): 30,\n",
              " ('suppos', 1.0): 6,\n",
              " ('lol', 1.0): 48,\n",
              " ('chat', 1.0): 9,\n",
              " ('bit', 1.0): 16,\n",
              " ('youth', 1.0): 14,\n",
              " ('üíÖüèΩ', 1.0): 1,\n",
              " ('üíã', 1.0): 2,\n",
              " ('seen', 1.0): 6,\n",
              " ('year', 1.0): 33,\n",
              " ('rest', 1.0): 9,\n",
              " ('goe', 1.0): 4,\n",
              " ('quickli', 1.0): 3,\n",
              " ('bed', 1.0): 8,\n",
              " ('music', 1.0): 15,\n",
              " ('fix', 1.0): 6,\n",
              " ('dream', 1.0): 17,\n",
              " ('spiritu', 1.0): 1,\n",
              " ('ritual', 1.0): 1,\n",
              " ('festiv', 1.0): 7,\n",
              " ('n√©pal', 1.0): 1,\n",
              " ('begin', 1.0): 4,\n",
              " ('line-up', 1.0): 4,\n",
              " ('left', 1.0): 10,\n",
              " ('see', 1.0): 156,\n",
              " ('sarah', 1.0): 4,\n",
              " ('send', 1.0): 17,\n",
              " ('us', 1.0): 91,\n",
              " ('email', 1.0): 22,\n",
              " ('bitsy@bitdefender.com', 1.0): 1,\n",
              " (\"we'll\", 1.0): 12,\n",
              " ('asap', 1.0): 5,\n",
              " ('kik', 1.0): 16,\n",
              " ('hatessuc', 1.0): 1,\n",
              " ('32429', 1.0): 1,\n",
              " ('kikm', 1.0): 1,\n",
              " ('lgbt', 1.0): 2,\n",
              " ('tinder', 1.0): 1,\n",
              " ('nsfw', 1.0): 1,\n",
              " ('akua', 1.0): 1,\n",
              " ('cumshot', 1.0): 1,\n",
              " ('come', 1.0): 63,\n",
              " ('hous', 1.0): 5,\n",
              " ('nsn_supplement', 1.0): 1,\n",
              " ('effect', 1.0): 2,\n",
              " ('press', 1.0): 1,\n",
              " ('releas', 1.0): 11,\n",
              " ('distribut', 1.0): 1,\n",
              " ('result', 1.0): 2,\n",
              " ('link', 1.0): 13,\n",
              " ('remov', 1.0): 3,\n",
              " ('pressreleas', 1.0): 1,\n",
              " ('newsdistribut', 1.0): 1,\n",
              " ('bam', 1.0): 44,\n",
              " ('bestfriend', 1.0): 50,\n",
              " ('lot', 1.0): 80,\n",
              " ('warsaw', 1.0): 44,\n",
              " ('<3', 1.0): 118,\n",
              " ('x46', 1.0): 1,\n",
              " ('everyon', 1.0): 45,\n",
              " ('watch', 1.0): 32,\n",
              " ('documentari', 1.0): 1,\n",
              " ('earthl', 1.0): 1,\n",
              " ('youtub', 1.0): 8,\n",
              " ('support', 1.0): 25,\n",
              " ('buuut', 1.0): 1,\n",
              " ('oh', 1.0): 44,\n",
              " ('look', 1.0): 109,\n",
              " ('forward', 1.0): 20,\n",
              " ('visit', 1.0): 25,\n",
              " ('next', 1.0): 37,\n",
              " ('letsgetmessi', 1.0): 1,\n",
              " ('jo', 1.0): 1,\n",
              " ('make', 1.0): 69,\n",
              " ('feel', 1.0): 33,\n",
              " ('better', 1.0): 40,\n",
              " ('never', 1.0): 31,\n",
              " ('anyon', 1.0): 7,\n",
              " ('kpop', 1.0): 1,\n",
              " ('flesh', 1.0): 1,\n",
              " ('good', 1.0): 191,\n",
              " ('girl', 1.0): 34,\n",
              " ('best', 1.0): 49,\n",
              " ('wish', 1.0): 29,\n",
              " ('reason', 1.0): 10,\n",
              " ('epic', 1.0): 1,\n",
              " ('soundtrack', 1.0): 1,\n",
              " ('shout', 1.0): 11,\n",
              " ('ad', 1.0): 10,\n",
              " ('video', 1.0): 29,\n",
              " ('playlist', 1.0): 5,\n",
              " ('would', 1.0): 70,\n",
              " ('dear', 1.0): 15,\n",
              " ('jordan', 1.0): 1,\n",
              " ('okay', 1.0): 31,\n",
              " ('fake', 1.0): 1,\n",
              " ('gameplay', 1.0): 1,\n",
              " (';)', 1.0): 22,\n",
              " ('haha', 1.0): 44,\n",
              " ('im', 1.0): 38,\n",
              " ('kid', 1.0): 13,\n",
              " ('stuff', 1.0): 11,\n",
              " ('exactli', 1.0): 5,\n",
              " ('product', 1.0): 11,\n",
              " ('line', 1.0): 6,\n",
              " ('etsi', 1.0): 1,\n",
              " ('shop', 1.0): 12,\n",
              " ('check', 1.0): 38,\n",
              " ('vacat', 1.0): 5,\n",
              " ('recharg', 1.0): 1,\n",
              " ('normal', 1.0): 5,\n",
              " ('charger', 1.0): 2,\n",
              " ('asleep', 1.0): 7,\n",
              " ('talk', 1.0): 37,\n",
              " ('sooo', 1.0): 6,\n",
              " ('someon', 1.0): 29,\n",
              " ('text', 1.0): 12,\n",
              " ('ye', 1.0): 60,\n",
              " ('bet', 1.0): 6,\n",
              " (\"he'll\", 1.0): 2,\n",
              " ('fit', 1.0): 2,\n",
              " ('hear', 1.0): 24,\n",
              " ('speech', 1.0): 1,\n",
              " ('piti', 1.0): 2,\n",
              " ('green', 1.0): 2,\n",
              " ('garden', 1.0): 5,\n",
              " ('midnight', 1.0): 1,\n",
              " ('sun', 1.0): 6,\n",
              " ('beauti', 1.0): 45,\n",
              " ('canal', 1.0): 1,\n",
              " ('dasvidaniya', 1.0): 1,\n",
              " ('till', 1.0): 16,\n",
              " ('scout', 1.0): 1,\n",
              " ('sg', 1.0): 1,\n",
              " ('futur', 1.0): 9,\n",
              " ('wlan', 1.0): 1,\n",
              " ('pro', 1.0): 4,\n",
              " ('confer', 1.0): 1,\n",
              " ('asia', 1.0): 1,\n",
              " ('chang', 1.0): 20,\n",
              " ('lollipop', 1.0): 1,\n",
              " ('üç≠', 1.0): 1,\n",
              " ('nez', 1.0): 1,\n",
              " ('agnezmo', 1.0): 1,\n",
              " ('oley', 1.0): 1,\n",
              " ('mama', 1.0): 1,\n",
              " ('stand', 1.0): 6,\n",
              " ('stronger', 1.0): 1,\n",
              " ('god', 1.0): 14,\n",
              " ('misti', 1.0): 1,\n",
              " ('babi', 1.0): 17,\n",
              " ('cute', 1.0): 21,\n",
              " ('woohoo', 1.0): 3,\n",
              " (\"can't\", 1.0): 31,\n",
              " ('sign', 1.0): 9,\n",
              " ('yet', 1.0): 12,\n",
              " ('still', 1.0): 37,\n",
              " ('think', 1.0): 48,\n",
              " ('mka', 1.0): 5,\n",
              " ('liam', 1.0): 5,\n",
              " ('access', 1.0): 3,\n",
              " ('welcom', 1.0): 54,\n",
              " ('stat', 1.0): 51,\n",
              " ('arriv', 1.0): 57,\n",
              " ('1', 1.0): 60,\n",
              " ('unfollow', 1.0): 53,\n",
              " ('via', 1.0): 60,\n",
              " ('surpris', 1.0): 10,\n",
              " ('figur', 1.0): 5,\n",
              " ('happybirthdayemilybett', 1.0): 1,\n",
              " ('sweet', 1.0): 16,\n",
              " ('talent', 1.0): 4,\n",
              " ('2', 1.0): 41,\n",
              " ('plan', 1.0): 21,\n",
              " ('drain', 1.0): 1,\n",
              " ('gotta', 1.0): 4,\n",
              " ('timezon', 1.0): 1,\n",
              " ('parent', 1.0): 4,\n",
              " ('proud', 1.0): 11,\n",
              " ('least', 1.0): 14,\n",
              " ('mayb', 1.0): 17,\n",
              " ('sometim', 1.0): 11,\n",
              " ('grade', 1.0): 4,\n",
              " ('al', 1.0): 3,\n",
              " ('grand', 1.0): 4,\n",
              " ('manila_bro', 1.0): 1,\n",
              " ('chosen', 1.0): 1,\n",
              " ('let', 1.0): 57,\n",
              " ('around', 1.0): 14,\n",
              " ('..', 1.0): 100,\n",
              " ('side', 1.0): 13,\n",
              " ('world', 1.0): 23,\n",
              " ('eh', 1.0): 2,\n",
              " ('take', 1.0): 30,\n",
              " ('care', 1.0): 12,\n",
              " ('final', 1.0): 24,\n",
              " ('fuck', 1.0): 20,\n",
              " ('weekend', 1.0): 61,\n",
              " ('real', 1.0): 18,\n",
              " ('x45', 1.0): 1,\n",
              " ('join', 1.0): 21,\n",
              " ('hushedcallwithfraydo', 1.0): 1,\n",
              " ('gift', 1.0): 7,\n",
              " ('yeahhh', 1.0): 1,\n",
              " ('hushedpinwithsammi', 1.0): 2,\n",
              " ('event', 1.0): 7,\n",
              " ('might', 1.0): 21,\n",
              " ('luv', 1.0): 4,\n",
              " ('realli', 1.0): 66,\n",
              " ('appreci', 1.0): 28,\n",
              " ('share', 1.0): 41,\n",
              " ('wow', 1.0): 14,\n",
              " ('tom', 1.0): 5,\n",
              " ('gym', 1.0): 3,\n",
              " ('monday', 1.0): 7,\n",
              " ('invit', 1.0): 15,\n",
              " ('scope', 1.0): 5,\n",
              " ('friend', 1.0): 40,\n",
              " ('nude', 1.0): 1,\n",
              " ('sleep', 1.0): 35,\n",
              " ('birthday', 1.0): 53,\n",
              " ('want', 1.0): 69,\n",
              " ('t-shirt', 1.0): 2,\n",
              " ('cool', 1.0): 29,\n",
              " ('haw', 1.0): 1,\n",
              " ('phela', 1.0): 1,\n",
              " ('mom', 1.0): 7,\n",
              " ('obvious', 1.0): 1,\n",
              " ('princ', 1.0): 1,\n",
              " ('charm', 1.0): 1,\n",
              " ('stage', 1.0): 2,\n",
              " ('luck', 1.0): 26,\n",
              " ('tyler', 1.0): 1,\n",
              " ('hipster', 1.0): 1,\n",
              " ('glass', 1.0): 3,\n",
              " ('marti', 1.0): 2,\n",
              " ('glad', 1.0): 41,\n",
              " ('done', 1.0): 40,\n",
              " ('afternoon', 1.0): 7,\n",
              " ('read', 1.0): 27,\n",
              " ('kahfi', 1.0): 1,\n",
              " ('finish', 1.0): 15,\n",
              " ('ohmyg', 1.0): 1,\n",
              " ('yaya', 1.0): 3,\n",
              " ('dub', 1.0): 1,\n",
              " ('stalk', 1.0): 2,\n",
              " ('ig', 1.0): 3,\n",
              " ('gondooo', 1.0): 1,\n",
              " ('moo', 1.0): 2,\n",
              " ('tologooo', 1.0): 1,\n",
              " ('becom', 1.0): 8,\n",
              " ('detail', 1.0): 8,\n",
              " ('zzz', 1.0): 1,\n",
              " ('xx', 1.0): 33,\n",
              " ('physiotherapi', 1.0): 1,\n",
              " ('hashtag', 1.0): 3,\n",
              " ('üí™', 1.0): 1,\n",
              " ('monica', 1.0): 1,\n",
              " ('miss', 1.0): 17,\n",
              " ('sound', 1.0): 20,\n",
              " ('morn', 1.0): 68,\n",
              " (\"that'\", 1.0): 49,\n",
              " ('x43', 1.0): 1,\n",
              " ('definit', 1.0): 20,\n",
              " ('tri', 1.0): 34,\n",
              " ('tonight', 1.0): 15,\n",
              " ('took', 1.0): 7,\n",
              " ('advic', 1.0): 6,\n",
              " ('treviso', 1.0): 1,\n",
              " ('concert', 1.0): 23,\n",
              " ('citi', 1.0): 26,\n",
              " ('countri', 1.0): 22,\n",
              " (\"i'll\", 1.0): 73,\n",
              " ('start', 1.0): 56,\n",
              " ('fine', 1.0): 7,\n",
              " ('gorgeou', 1.0): 9,\n",
              " ('xo', 1.0): 2,\n",
              " ('oven', 1.0): 2,\n",
              " ('roast', 1.0): 1,\n",
              " ('garlic', 1.0): 1,\n",
              " ('oliv', 1.0): 1,\n",
              " ('oil', 1.0): 4,\n",
              " ('dri', 1.0): 4,\n",
              " ('tomato', 1.0): 1,\n",
              " ('basil', 1.0): 1,\n",
              " ('centuri', 1.0): 1,\n",
              " ('tuna', 1.0): 1,\n",
              " ('right', 1.0): 38,\n",
              " ('back', 1.0): 74,\n",
              " ('atchya', 1.0): 1,\n",
              " ('even', 1.0): 26,\n",
              " ('almost', 1.0): 8,\n",
              " ('chanc', 1.0): 3,\n",
              " ('cheer', 1.0): 17,\n",
              " ('po', 1.0): 3,\n",
              " ('ice', 1.0): 6,\n",
              " ('cream', 1.0): 6,\n",
              " ('agre', 1.0): 13,\n",
              " ('100', 1.0): 6,\n",
              " ('heheheh', 1.0): 2,\n",
              " ('that', 1.0): 10,\n",
              " ('point', 1.0): 11,\n",
              " ('stay', 1.0): 20,\n",
              " ('home', 1.0): 20,\n",
              " ('soon', 1.0): 38,\n",
              " ('promis', 1.0): 4,\n",
              " ('web', 1.0): 4,\n",
              " ('whatsapp', 1.0): 3,\n",
              " ('volta', 1.0): 1,\n",
              " ('funcionar', 1.0): 1,\n",
              " ('com', 1.0): 2,\n",
              " ('iphon', 1.0): 7,\n",
              " ('jailbroken', 1.0): 1,\n",
              " ('later', 1.0): 11,\n",
              " ('34', 1.0): 3,\n",
              " ('min', 1.0): 7,\n",
              " ('leia', 1.0): 1,\n",
              " ('appear', 1.0): 3,\n",
              " ('hologram', 1.0): 1,\n",
              " ('r2d2', 1.0): 1,\n",
              " ('w', 1.0): 16,\n",
              " ('messag', 1.0): 9,\n",
              " ('obi', 1.0): 1,\n",
              " ('wan', 1.0): 1,\n",
              " ('sit', 1.0): 7,\n",
              " ('luke', 1.0): 4,\n",
              " ('inter', 1.0): 1,\n",
              " ('3', 1.0): 25,\n",
              " ('ucl', 1.0): 1,\n",
              " ('arsen', 1.0): 2,\n",
              " ('small', 1.0): 1,\n",
              " ('team', 1.0): 24,\n",
              " ('pass', 1.0): 10,\n",
              " ('üöÇ', 1.0): 1,\n",
              " ('dewsburi', 1.0): 2,\n",
              " ('railway', 1.0): 1,\n",
              " ('station', 1.0): 4,\n",
              " ('dew', 1.0): 1,\n",
              " ('west', 1.0): 1,\n",
              " ('yorkshir', 1.0): 2,\n",
              " ('430', 1.0): 1,\n",
              " ('smh', 1.0): 2,\n",
              " ('9:25', 1.0): 1,\n",
              " ('live', 1.0): 21,\n",
              " ('strang', 1.0): 4,\n",
              " ('imagin', 1.0): 5,\n",
              " ('megan', 1.0): 1,\n",
              " ('masaantoday', 1.0): 4,\n",
              " ('a4', 1.0): 3,\n",
              " ('shweta', 1.0): 1,\n",
              " ('tripathi', 1.0): 1,\n",
              " ('5', 1.0): 15,\n",
              " ('20', 1.0): 5,\n",
              " ('kurta', 1.0): 3,\n",
              " ('half', 1.0): 6,\n",
              " ('number', 1.0): 11,\n",
              " ('wsalelov', 1.0): 14,\n",
              " ('ah', 1.0): 12,\n",
              " ('larri', 1.0): 3,\n",
              " ('anyway', 1.0): 14,\n",
              " ('kinda', 1.0): 12,\n",
              " ('goood', 1.0): 1,\n",
              " ('life', 1.0): 36,\n",
              " ('enn', 1.0): 1,\n",
              " ('could', 1.0): 25,\n",
              " ('warmup', 1.0): 1,\n",
              " ('15th', 1.0): 2,\n",
              " ('bath', 1.0): 6,\n",
              " ('dum', 1.0): 2,\n",
              " ('andar', 1.0): 1,\n",
              " ('ram', 1.0): 1,\n",
              " ('sampath', 1.0): 1,\n",
              " ('sona', 1.0): 1,\n",
              " ('mohapatra', 1.0): 1,\n",
              " ('samantha', 1.0): 1,\n",
              " ('edward', 1.0): 1,\n",
              " ('mein', 1.0): 1,\n",
              " ('tulan', 1.0): 1,\n",
              " ('razi', 1.0): 2,\n",
              " ('wah', 1.0): 2,\n",
              " ('josh', 1.0): 1,\n",
              " ('alway', 1.0): 48,\n",
              " ('smile', 1.0): 47,\n",
              " ('pictur', 1.0): 7,\n",
              " ('16.20', 1.0): 1,\n",
              " ('giveitup', 1.0): 1,\n",
              " ('given', 1.0): 3,\n",
              " ('ga', 1.0): 3,\n",
              " ('subsidi', 1.0): 1,\n",
              " ('initi', 1.0): 2,\n",
              " ('propos', 1.0): 3,\n",
              " ('delight', 1.0): 4,\n",
              " ('yesterday', 1.0): 4,\n",
              " ('x42', 1.0): 1,\n",
              " ('lmaoo', 1.0): 2,\n",
              " ('song', 1.0): 16,\n",
              " ('ever', 1.0): 19,\n",
              " ('shall', 1.0): 5,\n",
              " ('littl', 1.0): 29,\n",
              " ('throwback', 1.0): 3,\n",
              " ('outli', 1.0): 1,\n",
              " ('island', 1.0): 2,\n",
              " ('cheung', 1.0): 1,\n",
              " ('chau', 1.0): 1,\n",
              " ('mui', 1.0): 1,\n",
              " ('wo', 1.0): 1,\n",
              " ('total', 1.0): 5,\n",
              " ('differ', 1.0): 10,\n",
              " ('kfckitchentour', 1.0): 2,\n",
              " ('kitchen', 1.0): 3,\n",
              " ('clean', 1.0): 1,\n",
              " (\"i'm\", 1.0): 140,\n",
              " ('cusp', 1.0): 1,\n",
              " ('test', 1.0): 7,\n",
              " ('water', 1.0): 7,\n",
              " ('reward', 1.0): 1,\n",
              " ('arummzz', 1.0): 2,\n",
              " (\"let'\", 1.0): 18,\n",
              " ('drive', 1.0): 9,\n",
              " ('travel', 1.0): 19,\n",
              " ('yogyakarta', 1.0): 3,\n",
              " ('jeep', 1.0): 3,\n",
              " ('indonesia', 1.0): 3,\n",
              " ('instamood', 1.0): 3,\n",
              " ('wanna', 1.0): 23,\n",
              " ('skype', 1.0): 3,\n",
              " ('may', 1.0): 16,\n",
              " ('nice', 1.0): 70,\n",
              " ('friendli', 1.0): 1,\n",
              " ('pretend', 1.0): 2,\n",
              " ('film', 1.0): 8,\n",
              " ('congratul', 1.0): 9,\n",
              " ('winner', 1.0): 3,\n",
              " ('cheesydelight', 1.0): 1,\n",
              " ('contest', 1.0): 5,\n",
              " ('address', 1.0): 8,\n",
              " ('guy', 1.0): 48,\n",
              " ('market', 1.0): 5,\n",
              " ('24/7', 1.0): 1,\n",
              " ('14', 1.0): 1,\n",
              " ('hour', 1.0): 24,\n",
              " ('leav', 1.0): 11,\n",
              " ('without', 1.0): 9,\n",
              " ('delay', 1.0): 1,\n",
              " ('actual', 1.0): 13,\n",
              " ('easi', 1.0): 7,\n",
              " ('guess', 1.0): 8,\n",
              " ('train', 1.0): 7,\n",
              " ('wd', 1.0): 1,\n",
              " ('shift', 1.0): 4,\n",
              " ('engin', 1.0): 1,\n",
              " ('etc', 1.0): 2,\n",
              " ('sunburn', 1.0): 1,\n",
              " ('peel', 1.0): 2,\n",
              " ('blog', 1.0): 27,\n",
              " ('huge', 1.0): 9,\n",
              " ('warm', 1.0): 4,\n",
              " ('‚òÜ', 1.0): 3,\n",
              " ('complet', 1.0): 10,\n",
              " ('triangl', 1.0): 2,\n",
              " ('northern', 1.0): 1,\n",
              " ('ireland', 1.0): 2,\n",
              " ('sight', 1.0): 1,\n",
              " ('smthng', 1.0): 2,\n",
              " ('fr', 1.0): 3,\n",
              " ('hug', 1.0): 11,\n",
              " ('xoxo', 1.0): 3,\n",
              " ('uu', 1.0): 1,\n",
              " ('jaann', 1.0): 1,\n",
              " ('topnewfollow', 1.0): 2,\n",
              " ('connect', 1.0): 13,\n",
              " ('wonder', 1.0): 26,\n",
              " ('made', 1.0): 38,\n",
              " ('fluffi', 1.0): 1,\n",
              " ('insid', 1.0): 7,\n",
              " ('pirouett', 1.0): 1,\n",
              " ('moos', 1.0): 1,\n",
              " ('trip', 1.0): 12,\n",
              " ('philli', 1.0): 1,\n",
              " ('decemb', 1.0): 2,\n",
              " (\"i'd\", 1.0): 13,\n",
              " ('dude', 1.0): 6,\n",
              " ('x41', 1.0): 1,\n",
              " ('question', 1.0): 15,\n",
              " ('flaw', 1.0): 1,\n",
              " ('pain', 1.0): 8,\n",
              " ('negat', 1.0): 1,\n",
              " ('strength', 1.0): 2,\n",
              " ('went', 1.0): 10,\n",
              " ('solo', 1.0): 4,\n",
              " ('move', 1.0): 9,\n",
              " ('fav', 1.0): 11,\n",
              " ('nirvana', 1.0): 1,\n",
              " ('smell', 1.0): 2,\n",
              " ('teen', 1.0): 3,\n",
              " ('spirit', 1.0): 1,\n",
              " ('rip', 1.0): 3,\n",
              " ('ami', 1.0): 4,\n",
              " ('winehous', 1.0): 1,\n",
              " ('coupl', 1.0): 5,\n",
              " ('tomhiddleston', 1.0): 1,\n",
              " ('elizabetholsen', 1.0): 1,\n",
              " ('yaytheylookgreat', 1.0): 1,\n",
              " ('goodnight', 1.0): 18,\n",
              " ('vid', 1.0): 8,\n",
              " ('wake', 1.0): 10,\n",
              " ('gonna', 1.0): 16,\n",
              " ('shoot', 1.0): 5,\n",
              " ('itti', 1.0): 2,\n",
              " ('bitti', 1.0): 2,\n",
              " ('teeni', 1.0): 2,\n",
              " ('bikini', 1.0): 3,\n",
              " ('much', 1.0): 73,\n",
              " ('4th', 1.0): 4,\n",
              " ('togeth', 1.0): 6,\n",
              " ('end', 1.0): 13,\n",
              " ('xfile', 1.0): 1,\n",
              " ('content', 1.0): 3,\n",
              " ('rain', 1.0): 18,\n",
              " ('fabul', 1.0): 4,\n",
              " ('fantast', 1.0): 8,\n",
              " ('‚ô°', 1.0): 12,\n",
              " ('jb', 1.0): 1,\n",
              " ('forev', 1.0): 5,\n",
              " ('belieb', 1.0): 3,\n",
              " ('nighti', 1.0): 1,\n",
              " ('bug', 1.0): 2,\n",
              " ('bite', 1.0): 1,\n",
              " ('bracelet', 1.0): 2,\n",
              " ('idea', 1.0): 23,\n",
              " ('foundri', 1.0): 1,\n",
              " ('game', 1.0): 23,\n",
              " ('sens', 1.0): 6,\n",
              " ('pic', 1.0): 21,\n",
              " ('ef', 1.0): 1,\n",
              " ('phone', 1.0): 16,\n",
              " ('woot', 1.0): 2,\n",
              " ('derek', 1.0): 1,\n",
              " ('use', 1.0): 32,\n",
              " ('parkshar', 1.0): 1,\n",
              " ('gloucestershir', 1.0): 1,\n",
              " ('aaaahhh', 1.0): 1,\n",
              " ('man', 1.0): 16,\n",
              " ('traffic', 1.0): 2,\n",
              " ('stress', 1.0): 4,\n",
              " ('reliev', 1.0): 1,\n",
              " (\"how'r\", 1.0): 1,\n",
              " ('arbeloa', 1.0): 1,\n",
              " ('turn', 1.0): 13,\n",
              " ('17', 1.0): 2,\n",
              " ('omg', 1.0): 13,\n",
              " ('say', 1.0): 43,\n",
              " ('europ', 1.0): 1,\n",
              " ('rise', 1.0): 2,\n",
              " ('find', 1.0): 20,\n",
              " ('hard', 1.0): 9,\n",
              " ('believ', 1.0): 7,\n",
              " ('uncount', 1.0): 1,\n",
              " ('coz', 1.0): 2,\n",
              " ('unlimit', 1.0): 1,\n",
              " ('cours', 1.0): 11,\n",
              " ('teamposit', 1.0): 1,\n",
              " ('aldub', 1.0): 2,\n",
              " ('‚òï', 1.0): 3,\n",
              " ('rita', 1.0): 2,\n",
              " ('info', 1.0): 10,\n",
              " (\"we'd\", 1.0): 4,\n",
              " ('way', 1.0): 34,\n",
              " ('boy', 1.0): 13,\n",
              " ('x40', 1.0): 1,\n",
              " ('true', 1.0): 19,\n",
              " ('sethi', 1.0): 2,\n",
              " ('high', 1.0): 6,\n",
              " ('exe', 1.0): 1,\n",
              " ('skeem', 1.0): 1,\n",
              " ('saam', 1.0): 1,\n",
              " ('peopl', 1.0): 42,\n",
              " ('polit', 1.0): 2,\n",
              " ('izzat', 1.0): 1,\n",
              " ('wese', 1.0): 1,\n",
              " ('trust', 1.0): 7,\n",
              " ('khawateen', 1.0): 1,\n",
              " ('k', 1.0): 8,\n",
              " ('sath', 1.0): 2,\n",
              " ('mana', 1.0): 1,\n",
              " ('kar', 1.0): 1,\n",
              " ('deya', 1.0): 1,\n",
              " ('sort', 1.0): 7,\n",
              " ('smart', 1.0): 5,\n",
              " ('hair', 1.0): 7,\n",
              " ('tbh', 1.0): 5,\n",
              " ('jacob', 1.0): 2,\n",
              " ('g', 1.0): 7,\n",
              " ('upgrad', 1.0): 2,\n",
              " ('tee', 1.0): 2,\n",
              " ('famili', 1.0): 14,\n",
              " ('person', 1.0): 14,\n",
              " ('two', 1.0): 15,\n",
              " ('convers', 1.0): 6,\n",
              " ('onlin', 1.0): 4,\n",
              " ('mclaren', 1.0): 1,\n",
              " ('fridayfeel', 1.0): 5,\n",
              " ('tgif', 1.0): 8,\n",
              " ('squar', 1.0): 1,\n",
              " ('enix', 1.0): 1,\n",
              " ('bissmillah', 1.0): 1,\n",
              " ('ya', 1.0): 19,\n",
              " ('allah', 1.0): 3,\n",
              " (\"we'r\", 1.0): 25,\n",
              " ('socent', 1.0): 1,\n",
              " ('startup', 1.0): 2,\n",
              " ('drop', 1.0): 9,\n",
              " ('your', 1.0): 3,\n",
              " ('arnd', 1.0): 1,\n",
              " ('town', 1.0): 3,\n",
              " ('basic', 1.0): 4,\n",
              " ('piss', 1.0): 2,\n",
              " ('cup', 1.0): 4,\n",
              " ('also', 1.0): 28,\n",
              " ('terribl', 1.0): 2,\n",
              " ('complic', 1.0): 1,\n",
              " ('discuss', 1.0): 2,\n",
              " ('snapchat', 1.0): 31,\n",
              " ('lynettelow', 1.0): 1,\n",
              " ('kikmenow', 1.0): 2,\n",
              " ('snapm', 1.0): 1,\n",
              " ('hot', 1.0): 20,\n",
              " ('amazon', 1.0): 1,\n",
              " ('kikmeguy', 1.0): 2,\n",
              " ('defin', 1.0): 2,\n",
              " ('grow', 1.0): 6,\n",
              " ('sport', 1.0): 4,\n",
              " ('rt', 1.0): 9,\n",
              " ('rakyat', 1.0): 1,\n",
              " ('write', 1.0): 11,\n",
              " ('sinc', 1.0): 11,\n",
              " ('mention', 1.0): 18,\n",
              " ('fli', 1.0): 5,\n",
              " ('fish', 1.0): 3,\n",
              " ('promot', 1.0): 3,\n",
              " ('post', 1.0): 16,\n",
              " ('cyber', 1.0): 1,\n",
              " ('ourdaughtersourprid', 1.0): 3,\n",
              " ('mypapamyprid', 1.0): 2,\n",
              " ('papa', 1.0): 1,\n",
              " ('coach', 1.0): 2,\n",
              " ('posit', 1.0): 3,\n",
              " ('kha', 1.0): 1,\n",
              " ('atleast', 1.0): 2,\n",
              " ('x39', 1.0): 1,\n",
              " ('mango', 1.0): 1,\n",
              " (\"lassi'\", 1.0): 1,\n",
              " (\"monty'\", 1.0): 1,\n",
              " ('marvel', 1.0): 2,\n",
              " ('though', 1.0): 16,\n",
              " ('suspect', 1.0): 3,\n",
              " ('meant', 1.0): 2,\n",
              " ('24', 1.0): 3,\n",
              " ('hr', 1.0): 2,\n",
              " ('touch', 1.0): 7,\n",
              " ('kepler', 1.0): 3,\n",
              " ('452b', 1.0): 4,\n",
              " ('chalna', 1.0): 1,\n",
              " ('hai', 1.0): 7,\n",
              " ('thankyou', 1.0): 12,\n",
              " ('hazel', 1.0): 1,\n",
              " ('food', 1.0): 6,\n",
              " ('brooklyn', 1.0): 1,\n",
              " ('pta', 1.0): 2,\n",
              " ('awak', 1.0): 8,\n",
              " ('okayi', 1.0): 2,\n",
              " ('awww', 1.0): 12,\n",
              " ('ha', 1.0): 18,\n",
              " ('doc', 1.0): 1,\n",
              " ('splendid', 1.0): 1,\n",
              " ('spam', 1.0): 1,\n",
              " ('folder', 1.0): 1,\n",
              " ('amount', 1.0): 1,\n",
              " ('nigeria', 1.0): 1,\n",
              " ('claim', 1.0): 1,\n",
              " ('rted', 1.0): 1,\n",
              " ('leg', 1.0): 3,\n",
              " ('hurt', 1.0): 4,\n",
              " ('bad', 1.0): 14,\n",
              " ('mine', 1.0): 11,\n",
              " ('saturday', 1.0): 5,\n",
              " ('thaaank', 1.0): 1,\n",
              " ('puhon', 1.0): 1,\n",
              " ('happinesss', 1.0): 1,\n",
              " ('tnc', 1.0): 1,\n",
              " ('prior', 1.0): 1,\n",
              " ('notif', 1.0): 2,\n",
              " ('fat', 1.0): 1,\n",
              " ('co', 1.0): 1,\n",
              " ('probabl', 1.0): 7,\n",
              " ('ate', 1.0): 4,\n",
              " ('yuna', 1.0): 2,\n",
              " ('tamesid', 1.0): 1,\n",
              " ('¬¥', 1.0): 3,\n",
              " ('googl', 1.0): 5,\n",
              " ('account', 1.0): 17,\n",
              " ('scouser', 1.0): 1,\n",
              " ('everyth', 1.0): 10,\n",
              " ('zoe', 1.0): 1,\n",
              " ('mate', 1.0): 5,\n",
              " ('liter', 1.0): 5,\n",
              " (\"they'r\", 1.0): 10,\n",
              " ('samee', 1.0): 1,\n",
              " ('edgar', 1.0): 1,\n",
              " ('updat', 1.0): 12,\n",
              " ('log', 1.0): 3,\n",
              " ('bring', 1.0): 12,\n",
              " ('abe', 1.0): 1,\n",
              " ('meet', 1.0): 26,\n",
              " ('x38', 1.0): 1,\n",
              " ('sigh', 1.0): 3,\n",
              " ('dreamili', 1.0): 1,\n",
              " ('pout', 1.0): 1,\n",
              " ('eye', 1.0): 12,\n",
              " ('quacketyquack', 1.0): 6,\n",
              " ('funni', 1.0): 15,\n",
              " ('happen', 1.0): 13,\n",
              " ('phil', 1.0): 1,\n",
              " ('em', 1.0): 2,\n",
              " ('del', 1.0): 1,\n",
              " ('rodder', 1.0): 1,\n",
              " ('els', 1.0): 8,\n",
              " ('play', 1.0): 37,\n",
              " ('newest', 1.0): 1,\n",
              " ('gamejam', 1.0): 1,\n",
              " ('irish', 1.0): 2,\n",
              " ('literatur', 1.0): 2,\n",
              " ('inaccess', 1.0): 2,\n",
              " (\"kareena'\", 1.0): 2,\n",
              " ('fan', 1.0): 21,\n",
              " ('brain', 1.0): 10,\n",
              " ('dot', 1.0): 8,\n",
              " ('braindot', 1.0): 8,\n",
              " ('fair', 1.0): 4,\n",
              " ('rush', 1.0): 1,\n",
              " ('either', 1.0): 10,\n",
              " ('brandi', 1.0): 1,\n",
              " ('18', 1.0): 5,\n",
              " ('carniv', 1.0): 1,\n",
              " ('men', 1.0): 8,\n",
              " ('put', 1.0): 11,\n",
              " ('mask', 1.0): 2,\n",
              " ('xavier', 1.0): 1,\n",
              " ('forneret', 1.0): 1,\n",
              " ('jennif', 1.0): 1,\n",
              " ('site', 1.0): 7,\n",
              " ('free', 1.0): 31,\n",
              " ('50.000', 1.0): 3,\n",
              " ('8', 1.0): 10,\n",
              " ('ball', 1.0): 7,\n",
              " ('pool', 1.0): 5,\n",
              " ('coin', 1.0): 5,\n",
              " ('edit', 1.0): 6,\n",
              " ('trish', 1.0): 1,\n",
              " ('‚ô•', 1.0): 13,\n",
              " ('grate', 1.0): 5,\n",
              " ('three', 1.0): 8,\n",
              " ('comment', 1.0): 7,\n",
              " ('wakeup', 1.0): 1,\n",
              " ('besid', 1.0): 2,\n",
              " ('dirti', 1.0): 2,\n",
              " ('sex', 1.0): 4,\n",
              " ('lmaooo', 1.0): 1,\n",
              " ('üò§', 1.0): 2,\n",
              " ('loui', 1.0): 4,\n",
              " (\"he'\", 1.0): 10,\n",
              " ('throw', 1.0): 3,\n",
              " ('caus', 1.0): 11,\n",
              " ('inspir', 1.0): 6,\n",
              " ('ff', 1.0): 40,\n",
              " ('twoof', 1.0): 3,\n",
              " ('gr8', 1.0): 1,\n",
              " ('wkend', 1.0): 3,\n",
              " ('kind', 1.0): 22,\n",
              " ('exhaust', 1.0): 2,\n",
              " ('word', 1.0): 17,\n",
              " ('cheltenham', 1.0): 1,\n",
              " ('area', 1.0): 4,\n",
              " ('kale', 1.0): 1,\n",
              " ('crisp', 1.0): 1,\n",
              " ('ruin', 1.0): 5,\n",
              " ('x37', 1.0): 1,\n",
              " ('open', 1.0): 12,\n",
              " ('worldwid', 1.0): 2,\n",
              " ('outta', 1.0): 1,\n",
              " ('sfvbeta', 1.0): 1,\n",
              " ('vantast', 1.0): 1,\n",
              " ('xcylin', 1.0): 1,\n",
              " ('bundl', 1.0): 1,\n",
              " ('show', 1.0): 20,\n",
              " ('internet', 1.0): 2,\n",
              " ('price', 1.0): 3,\n",
              " ('realisticli', 1.0): 1,\n",
              " ('pay', 1.0): 8,\n",
              " ('net', 1.0): 1,\n",
              " ('educ', 1.0): 1,\n",
              " ('power', 1.0): 6,\n",
              " ('weapon', 1.0): 1,\n",
              " ('nelson', 1.0): 1,\n",
              " ('mandela', 1.0): 1,\n",
              " ('recent', 1.0): 8,\n",
              " ('j', 1.0): 2,\n",
              " ('chenab', 1.0): 1,\n",
              " ('flow', 1.0): 5,\n",
              " ('pakistan', 1.0): 1,\n",
              " ('incredibleindia', 1.0): 1,\n",
              " ('teenchoic', 1.0): 7,\n",
              " ('choiceinternationalartist', 1.0): 7,\n",
              " ('superjunior', 1.0): 7,\n",
              " ('caught', 1.0): 4,\n",
              " ('first', 1.0): 41,\n",
              " ('salmon', 1.0): 1,\n",
              " ('super-blend', 1.0): 1,\n",
              " ('project', 1.0): 6,\n",
              " ('youth@bipolaruk.org.uk', 1.0): 1,\n",
              " ('awesom', 1.0): 35,\n",
              " ('stream', 1.0): 12,\n",
              " ('alma', 1.0): 1,\n",
              " ('mater', 1.0): 1,\n",
              " ('highschoolday', 1.0): 1,\n",
              " ('clientvisit', 1.0): 1,\n",
              " ('faith', 1.0): 3,\n",
              " ('christian', 1.0): 1,\n",
              " ('school', 1.0): 9,\n",
              " ('lizaminnelli', 1.0): 1,\n",
              " ('upcom', 1.0): 2,\n",
              " ('uk', 1.0): 4,\n",
              " ('üòÑ', 1.0): 3,\n",
              " ('singl', 1.0): 4,\n",
              " ('hill', 1.0): 4,\n",
              " ('everi', 1.0): 23,\n",
              " ('beat', 1.0): 7,\n",
              " ('wrong', 1.0): 9,\n",
              " ('readi', 1.0): 22,\n",
              " ('natur', 1.0): 1,\n",
              " ('pefumeri', 1.0): 1,\n",
              " ('workshop', 1.0): 2,\n",
              " ('neal', 1.0): 1,\n",
              " ('yard', 1.0): 1,\n",
              " ('covent', 1.0): 1,\n",
              " ('tomorrow', 1.0): 31,\n",
              " ('fback', 1.0): 26,\n",
              " ('indo', 1.0): 1,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ],
      "source": [
        "# Todas as frequencias\n",
        "freqs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd534c39",
      "metadata": {
        "id": "cd534c39"
      },
      "source": [
        "## Modelagem Preditiva\n",
        "\n",
        "Usaremos o algoritmo de Regress√£o Log√≠stica para classifica√ß√£o dos tweets em positivos ou negativos.\n",
        "\n",
        "Vamos construir cada etapa matem√°tica desse algoritmo."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4af6f91c",
      "metadata": {
        "id": "4af6f91c"
      },
      "source": [
        "### Parte 1:  Matem√°tica da Fun√ß√£o Sigm√≥ide\n",
        "\n",
        "A fun√ß√£o sigm√≥ide √© uma fun√ß√£o de ativa√ß√£o comumente usada em redes neurais. A fun√ß√£o sigm√≥ide √© definida como:\n",
        "\n",
        "$$ h(z) = \\frac{1}{1+\\exp^{-z}} $$\n",
        "\n",
        "Ela tem a forma de uma curva S, como mostrado abaixo:\n",
        "\n",
        "![title](imagens/sigmoid.png)\n",
        "\n",
        "A fun√ß√£o sigm√≥ide tem a seguintes propriedades:\n",
        "\n",
        "O valor de sa√≠da da fun√ß√£o sigm√≥ide est√° sempre entre 0 e 1. Isso torna a fun√ß√£o √∫til para problemas de classifica√ß√£o bin√°ria, pois pode ser interpretada como a probabilidade de um determinado exemplo pertencer √† classe positiva.\n",
        "\n",
        "A fun√ß√£o sigm√≥ide √© deriv√°vel em todos os pontos, o que a torna √∫til para o treinamento de redes neurais.\n",
        "\n",
        "A fun√ß√£o sigm√≥ide tem um gradiente muito pequeno para valores de entrada muito grandes ou muito pequenos. Isso pode causar problemas durante o treinamento da rede neural, pois pode levar ao \"estouro do gradiente\", um problema em que o gradiente fica muito grande e a rede neural deixa de aprender de maneira eficiente.\n",
        "\n",
        "Apesar desses problemas, a fun√ß√£o sigm√≥ide ainda √© usada em alguns casos, especialmente em problemas de classifica√ß√£o bin√°ria. No entanto, outras fun√ß√µes de ativa√ß√£o, como a ReLU e a tangente hiperb√≥lica, s√£o mais comumente usadas em redes neurais profundas devido ao seu desempenho melhor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a43405a",
      "metadata": {
        "id": "7a43405a"
      },
      "outputs": [],
      "source": [
        "# Criando a fun√ß√£o sigm√≥ide\n",
        "def sigmoid(z):\n",
        "    # Calcula o sigm√≥ide de z\n",
        "    h = 1 / (1 + np.exp(-z))\n",
        "    return h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ecea7c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ecea7c9",
        "outputId": "806ed03d-86c5-4aa4-87b8-0be2737f3f29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O valor para 1 √©: 0.7310585786300049\n",
            "O valor para 3,92 √©: 0.9805449154318069\n"
          ]
        }
      ],
      "source": [
        "# Testando a fun√ß√£o\n",
        "print('O valor para 1 √©:', sigmoid(1))\n",
        "print('O valor para 3,92 √©:', sigmoid(3.92))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3473f087",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3473f087",
        "outputId": "6bd29cb8-e4f2-49e9-f23f-1901202cdf35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CORRETO!\n"
          ]
        }
      ],
      "source": [
        "# Testando a fun√ß√£o\n",
        "if (sigmoid(1) == 0.7310585786300049):\n",
        "    print('CORRETO!')\n",
        "else:\n",
        "    print('INCORRETO!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efa3a104",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efa3a104",
        "outputId": "a29df509-64b3-4eef-8a56-8d0074e0c8ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INCORRETO!\n"
          ]
        }
      ],
      "source": [
        "# Testando a fun√ß√£o\n",
        "if (sigmoid(3.92) == 0.91):\n",
        "    print('CORRETO!')\n",
        "else:\n",
        "    print('INCORRETO!')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parte 2: Matem√°tica da Regress√£o Log√≠stica com a Fun√ß√£o Sigm√≥ide\n",
        "\n",
        "A regress√£o log√≠stica √© um modelo de aprendizado supervisionado usado para problemas de classifica√ß√£o bin√°ria. Ela √© baseada em uma fun√ß√£o de ativa√ß√£o chamada fun√ß√£o sigm√≥ide, que √© usada para estimar a probabilidade de um exemplo pertencer √† classe positiva.\n",
        "\n",
        "A equa√ß√£o b√°sica da regress√£o log√≠stica √© dada por:\n",
        "\n",
        "p = 1 / (1 + e^(-Wx + b))\n",
        "\n",
        "Onde p √© a probabilidade de um exemplo pertencer √† classe positiva, x √© o vetor de caracter√≠sticas de entrada, W √© a matriz de pesos e b √© o vi√©s.\n",
        "\n",
        "A fun√ß√£o sigm√≥ide √© usada para transformar a sa√≠da linear da regress√£o log√≠stica em uma probabilidade. Quando a sa√≠da √© maior que 0,5, o modelo prediz que o exemplo pertence √† classe positiva, enquanto que quando a sa√≠da √© menor que 0,5, o modelo prediz que o exemplo pertence √† classe negativa.\n",
        "\n",
        "Para treinar o modelo, usamos uma fun√ß√£o de custo chamada entropia cruzada, que mede o qu√£o incorretas s√£o as previs√µes do modelo. O objetivo √© minimizar a entropia cruzada ajustando os pesos W e o vi√©s b. Isso √© geralmente feito usando a descida do gradiente, um m√©todo de otimiza√ß√£o baseado em derivadas.\n",
        "\n",
        "Uma vez treinado, o modelo pode ser usado para fazer previs√µes para novos exemplos, usando a equa√ß√£o p = 1 / (1 + e^(-Wx + b)). Se a probabilidade p for maior que 0,5, o modelo prediz que o exemplo pertence √† classe positiva, caso contr√°rio, o modelo prediz que o exemplo pertence √† classe negativa.\n",
        "\n",
        "A regress√£o log√≠stica usa uma regress√£o linear regular e aplica um sigm√≥ide √† sa√≠da da regress√£o linear.\n",
        "\n",
        "Regress√£o:\n",
        "\n",
        "$$z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_N x_N$$\n",
        "\n",
        "Observe que valores $\\theta$ s√£o \"pesos\".\n",
        "\n",
        "Regress√£o Log√≠stica:\n",
        "\n",
        "$$z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_N x_N$$\n",
        "\n",
        "$$ h(z) = \\frac{1}{1+\\exp^{-z}}$$\n",
        "\n",
        "Vamos nos referir a 'z' como 'logits'."
      ],
      "metadata": {
        "id": "JSKno6qnk4-6"
      },
      "id": "JSKno6qnk4-6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parte 3: Matem√°tica da Fun√ß√£o de Custo\n",
        "\n",
        "A fun√ß√£o de custo usada para regress√£o log√≠stica √© a m√©dia da perda de log em todos os exemplos de treinamento:\n",
        "\n",
        "$$J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^m y^{(i)}\\log (h(z(\\theta)^{(i)})) + (1-y^{(i)})\\log (1-h(z(\\theta)^{(i)})) $$\n",
        "\n",
        "* $m$ √© o n√∫mero de exemplos de treinamento.\n",
        "* $y^{(i)}$ √© o r√≥tulo real do exemplo de treinamento 'i'.\n",
        "* $h(z^{(i)})$ √© a previs√£o do modelo para o exemplo de treinamento 'i'.\n",
        "\n",
        "A fun√ß√£o de perda para um √∫nico exemplo de treinamento √©\n",
        "\n",
        "$$ Loss = -1 \\times \\left( y^{(i)}\\log (h(z(\\theta)^{(i)})) + (1-y^{(i)})\\log (1-h(z(\\theta)^{(i)})) \\right)$$\n",
        "\n",
        "* Todos os valores de $h$ est√£o entre 0 e 1, ent√£o os logs ser√£o negativos. Essa √© a raz√£o do fator de -1 aplicado √† soma dos dois termos de perda.\n",
        "\n",
        "\n",
        "* Observe que quando o modelo prev√™ 1 ($h(z(\\theta)) = 1$) e o r√≥tulo 'y' tamb√©m √© 1, a perda para esse exemplo de treinamento √© 0.\n",
        "\n",
        "\n",
        "* Da mesma forma, quando o modelo prev√™ 0 ($h(z(\\theta)) = 0$) e o r√≥tulo real tamb√©m √© 0, a perda para esse exemplo de treinamento √© 0.\n",
        "\n",
        "\n",
        "* No entanto, quando a previs√£o do modelo est√° pr√≥xima de 1 ($h(z(\\theta)) = 0,9999$) e o r√≥tulo √© 0, o segundo termo da perda de log torna-se um grande n√∫mero negativo, que √© ent√£o multiplicado pelo total fator de -1 para convert√™-lo em um valor de perda positivo. $-1 \\times (1 - 0) \\times log(1 - 0.9999) \\approx 9.2$."
      ],
      "metadata": {
        "id": "NBM3HgFXk69o"
      },
      "id": "NBM3HgFXk69o"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parte 4: Matem√°tica da Atualiza√ß√£o dos Pesos (Descida do Gradiente)\n",
        "\n",
        "Para atualizar o vetor de peso $\\theta$, aplicamos a descida do gradiente para melhorar iterativamente as previs√µes do modelo.\n",
        "\n",
        "O gradiente da fun√ß√£o de custo $J$ em rela√ß√£o a um dos pesos $\\theta_j$ √©:\n",
        "\n",
        "$$\\nabla_{\\theta_j}J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m(h^{(i)}-y^{(i)})x^{(i)}_j $$\n",
        "\n",
        "* 'i' √© o √≠ndice em todos os exemplos de treinamento 'm'.\n",
        "* 'j' √© o √≠ndice do peso $\\theta_j$, ent√£o $x^{(i)}_j$ √© o recurso associado ao peso $\\theta_j$\n",
        "\n",
        "* Para atualizar o peso $\\theta_j$, ajustamos subtraindo uma fra√ß√£o do gradiente determinado por $\\alpha$:\n",
        "\n",
        "$$\\theta_j = \\theta_j - \\alpha \\times \\nabla_{\\theta_j}J(\\theta) $$\n",
        "\n",
        "* A taxa de aprendizado $\\alpha$ √© um valor que escolhemos para controlar o tamanho de uma √∫nica atualiza√ß√£o."
      ],
      "metadata": {
        "id": "NgBOj0tzk7uM"
      },
      "id": "NgBOj0tzk7uM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parte 5: Combinando Todas as Opera√ß√µes e Criando o Algoritmo\n",
        "\n",
        "* O n√∫mero de itera√ß√µes 'num_iters\" √© o n√∫mero de vezes que voc√™ usar√° todo o conjunto de treinamento (n√∫mero de passadas de treinamento).\n",
        "\n",
        "\n",
        "* Para cada itera√ß√£o, voc√™ calcular√° a fun√ß√£o de custo usando todos os exemplos de treinamento (existem 'm' exemplos de treinamento) e para todos os recursos.\n",
        "\n",
        "\n",
        "* Em vez de atualizar um √∫nico peso $\\theta_i$ de cada vez, podemos atualizar todos os pesos no vetor de coluna:\n",
        "\n",
        "$$\\mathbf{\\theta} = \\begin{pmatrix}\n",
        "\\theta_0\n",
        "\\\\\n",
        "\\theta_1\n",
        "\\\\\n",
        "\\theta_2\n",
        "\\\\\n",
        "\\vdots\n",
        "\\\\\n",
        "\\theta_n\n",
        "\\end{pmatrix}$$\n",
        "\n",
        "* $\\mathbf{\\theta}$ tem dimens√µes (n+1, 1), onde 'n' √© o n√∫mero de recursos e h√° mais um elemento para o termo de vi√©s $\\theta_0$.\n",
        "\n",
        "\n",
        "* Os 'logits', 'z', s√£o calculados multiplicando a matriz de caracter√≠sticas 'x' pelo vetor de peso 'theta'. $z = \\mathbf{x}\\mathbf{\\theta}$\n",
        "    * $\\mathbf{x}$ tem dimens√µes (m, n+1)\n",
        "    * $\\mathbf{\\theta}$: tem dimens√µes (n+1, 1)\n",
        "    * $\\mathbf{z}$: tem dimens√µes (m, 1)\n",
        "\n",
        "\n",
        "* A predi√ß√£o 'h', √© calculada aplicando o sigm√≥ide a cada elemento em 'z': $h(z) = sigmoid(z)$, e tem dimens√µes (m,1).\n",
        "\n",
        "\n",
        "* A fun√ß√£o de custo $J$ √© calculada atrav√©s do produto escalar dos vetores 'y' e 'log(h)'. Como 'y' e 'h' s√£o vetores coluna (m,1), fazemos a transposta do vetor para a esquerda, de modo que a multiplica√ß√£o da matriz de um vetor linha com o vetor coluna execute o produto escalar.\n",
        "\n",
        "$$J = \\frac{-1}{m} \\times \\left(\\mathbf{y}^T \\cdot log(\\mathbf{h}) + \\mathbf{(1-y)}^T \\cdot log(\\mathbf{1-h}) \\right)$$\n",
        "\n",
        "\n",
        "* A atualiza√ß√£o de $\\theta$ tamb√©m √© vetorizada. Como as dimens√µes de $\\mathbf{x}$ s√£o (m, n+1) e $\\mathbf{h}$ e $\\mathbf{y}$ s√£o (m, 1), precisamos transpor o $ \\mathbf{x}$ √† esquerda para realizar a multiplica√ß√£o de matrizes, o que resulta na resposta (n+1, 1) de que precisamos:\n",
        "\n",
        "$$\\mathbf{\\theta} = \\mathbf{\\theta} - \\frac{\\alpha}{m} \\times \\left( \\mathbf{x}^T \\cdot \\left( \\mathbf{h-y} \\right) \\right)$$"
      ],
      "metadata": {
        "id": "iObGBraGk8yT"
      },
      "id": "iObGBraGk8yT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5323bfcf",
      "metadata": {
        "id": "5323bfcf"
      },
      "outputs": [],
      "source": [
        "# Fun√ß√£o para o algoritmo de regress√£o log√≠stica\n",
        "# Theta: Pesos\n",
        "# Alpha: Taxa de aprendizado\n",
        "def algo_reg_log(x, y, theta, alpha, num_iters):\n",
        "\n",
        "    # Obter 'm', o n√∫mero de linhas na matriz x\n",
        "    m = x.shape[0]\n",
        "\n",
        "    for i in range(0, num_iters):\n",
        "\n",
        "        # Obter z, o produto escalar de x e teta\n",
        "        z = np.dot(x,theta)\n",
        "\n",
        "        # Obter sigmoid de h\n",
        "        h = sigmoid(z)\n",
        "\n",
        "        # Calcula a fun√ß√£o de custo\n",
        "        # Note que podemos usar tamb√©m np.array.transpose() ao inv√©s de np.array.T\n",
        "        # np.array.T apenas torna o c√≥digo um pouco mais leg√≠vel\n",
        "        J = -1./m * (np.dot(y.T, np.log(h)) + np.dot((1-y).T, np.log(1-h)))\n",
        "\n",
        "        # Atualiza os pesos theta\n",
        "        theta = theta - (alpha/m) * np.dot(x.T,(h-y))\n",
        "\n",
        "    J = float(J)\n",
        "\n",
        "    return J, theta\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f7fdcd0",
      "metadata": {
        "id": "9f7fdcd0"
      },
      "outputs": [],
      "source": [
        "# Seed\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69e4b877",
      "metadata": {
        "id": "69e4b877"
      },
      "outputs": [],
      "source": [
        "# A entrada X √© um array 10 x 3 com 1 para o termo de vi√©s\n",
        "dados_X = np.append(np.ones((10, 1)), np.random.rand(10, 2) * 2000, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5eb7c89d",
      "metadata": {
        "id": "5eb7c89d"
      },
      "outputs": [],
      "source": [
        "# Labels Y s√£o array 10 x 1\n",
        "dados_Y = (np.random.rand(10, 1) > 0.35).astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "364525dd",
      "metadata": {
        "id": "364525dd"
      },
      "outputs": [],
      "source": [
        "# Aplica a fun√ß√£o\n",
        "valor_J, valor_theta = algo_reg_log(dados_X, dados_Y, np.zeros((3, 1)), 1e-8, 700)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65d14dd9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65d14dd9",
        "outputId": "df93ef4a-d133-406e-ae80-e067c891f40a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Custo (erro) ap√≥s o treinamento √© 0.46889301\n",
            "\n",
            "O vetor de pesos resultante √© [6e-08, -0.00068256, 0.00097]\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nCusto (erro) ap√≥s o treinamento √© {valor_J:.8f}\")\n",
        "print(f\"\\nO vetor de pesos resultante √© {[round(t, 8) for t in np.squeeze(valor_theta)]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra√ß√£o de Atributos\n",
        "\n",
        "Com o algoritmo pronto vamos extrair os atributos dos dados e treinar um modelo.\n",
        "\n",
        "* Dada uma lista de tweets, extra√≠mos os recursos e armazenamos em um vetor. Vamos extrair dois recursos:\n",
        "\n",
        "     * A primeira caracter√≠stica √© o n√∫mero de palavras positivas em um tweet.\n",
        "     * A segunda caracter√≠stica √© o n√∫mero de palavras negativas em um tweet.\n",
        "\n",
        "\n",
        "A fun√ß√£o abaixo realiza as seguintes tarefas:\n",
        "\n",
        "* Processa o tweet usando a fun√ß√£o `limpa_processa_tweet` e salvamos a lista de palavras do tweet.\n",
        "\n",
        "\n",
        "* Percorre cada palavra na lista de palavras processadas.\n",
        "\n",
        "\n",
        "* Para cada palavra, verificamos o dicion√°rio de frequ√™ncias 'freqs' para a contagem quando essa palavra tiver um r√≥tulo '1' positivo. Fazemos o mesmo para a contagem quando a palavra estiver associada ao r√≥tulo negativo '0'."
      ],
      "metadata": {
        "id": "uLm-RoEjjBZx"
      },
      "id": "uLm-RoEjjBZx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6f0e60d",
      "metadata": {
        "id": "a6f0e60d"
      },
      "outputs": [],
      "source": [
        "# Fun√ß√£o para extra√ß√£o de atributos\n",
        "def func_extract_features(tweet, freqs):\n",
        "\n",
        "    # Aplica a fun√ß√£o de limpeza e processamento\n",
        "    palavra_l = limpa_processa_tweet(tweet)\n",
        "\n",
        "    # Cria o vetor x de 3 elementos na forma 1 x 3\n",
        "    x = np.zeros((1, 3))\n",
        "\n",
        "    # O termo de bias ser√° definido como 1\n",
        "    x[0,0] = 1\n",
        "\n",
        "    # Loop pelas palavras\n",
        "    for palavra in palavra_l:\n",
        "\n",
        "        # Busca a frequencia da palavra de tweet positivo\n",
        "        x[0,1] += freqs.get((palavra, 1.0),0)\n",
        "\n",
        "        # Busca a frequencia da palavra de tweet negativo\n",
        "        x[0,2] += freqs.get((palavra, 0.0),0)\n",
        "\n",
        "    # Valida o shape\n",
        "    assert(x.shape == (1, 3))\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "165bde79",
      "metadata": {
        "id": "165bde79"
      },
      "source": [
        "## Treinamento do Modelo\n",
        "\n",
        "Para treinar o modelo:\n",
        "\n",
        "* Empilhamos os recursos de todos os exemplos de treinamento em uma matriz X.\n",
        "\n",
        "* Executamos o algoritmo `algo_reg_log`, implementado anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5135a1a3",
      "metadata": {
        "id": "5135a1a3"
      },
      "outputs": [],
      "source": [
        "# Criamos a matriz X\n",
        "X = np.zeros((len(dados_treino_x), 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c083c8e3",
      "metadata": {
        "id": "c083c8e3"
      },
      "outputs": [],
      "source": [
        "# Loop para preencher a matriz com os dados\n",
        "for i in range(len(dados_treino_x)):\n",
        "    X[i, :]= func_extract_features(dados_treino_x[i], freqs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "363ed613",
      "metadata": {
        "id": "363ed613"
      },
      "outputs": [],
      "source": [
        "# Vari√°vel de sa√≠da (target)\n",
        "Y = y_treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e57e134a",
      "metadata": {
        "id": "e57e134a"
      },
      "outputs": [],
      "source": [
        "# Hiperpar√¢metros\n",
        "\n",
        "# Valor inicial da matriz de pesos\n",
        "matriz_pesos = np.zeros((3, 1))\n",
        "\n",
        "# Taxa de aprendizado\n",
        "taxa_aprendizado_alfa = 1e-9\n",
        "\n",
        "# N√∫mero de itera√ß√µes\n",
        "num_iters = 1500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2362867",
      "metadata": {
        "id": "c2362867"
      },
      "outputs": [],
      "source": [
        "# Treinamento do modelo\n",
        "custo, pesos = algo_reg_log(X, Y, matriz_pesos, taxa_aprendizado_alfa, num_iters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7505066d",
      "metadata": {
        "id": "7505066d",
        "outputId": "ea063161-f852-4d25-cf38-15ce09bc4f31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O Custo (Erro) de Treinamento foi 0.24215478.\n"
          ]
        }
      ],
      "source": [
        "print(f\"O Custo (Erro) de Treinamento foi {custo:.8f}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f01e5816",
      "metadata": {
        "id": "f01e5816",
        "outputId": "d14826fe-be89-48ee-b382-6fc18a12d73d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O Vetor de Pesos √© [7e-08, 0.00052391, -0.00055517]\n"
          ]
        }
      ],
      "source": [
        "print(f\"O Vetor de Pesos √© {[round(t, 8) for t in np.squeeze(pesos)]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2a27fd5",
      "metadata": {
        "id": "e2a27fd5"
      },
      "source": [
        "S√£o 3 pesos pois temos 2 atributos de entrada e o bias."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db4e4b99",
      "metadata": {
        "id": "db4e4b99"
      },
      "source": [
        "## Previs√µes com o Modelo\n",
        "\n",
        "√â hora de fazer previs√µes com o modelo de regress√£o log√≠stica em alguma nova entrada de dados. O objetivo √© prever se um tweet tem sentimento positivo ou negativo.\n",
        "\n",
        "Vamos criar uma fun√ß√£o para isso que executar√° as seguintes tarefas:\n",
        "\n",
        "* Dado um tweet, processamos e extra√≠mos os recursos (o que mesmo que foi feito nso dados de treino).\n",
        "* Aplicamos os pesos aprendidos do modelo para obter os logits.\n",
        "* Aplicamos a fun√ß√£o sigm√≥ide aos logits para obter a previs√£o (um valor entre 0 e 1).\n",
        "\n",
        "Resumindo:\n",
        "\n",
        "$$y_{pred} = sigmoide(\\mathbf{x} \\cdot \\theta)$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8989f99a",
      "metadata": {
        "id": "8989f99a"
      },
      "outputs": [],
      "source": [
        "# Fun√ß√£o para previs√£o\n",
        "def func_previsao(tweet, freqs, pesos):\n",
        "\n",
        "    # Extrai os atributos\n",
        "    x = func_extract_features(tweet, freqs)\n",
        "\n",
        "    # Faz a previsao\n",
        "    y_pred = sigmoid(np.dot(x, pesos))\n",
        "\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8a50186",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "e8a50186",
        "outputId": "c27580a5-2c24-4222-e207-fd3e217c7b7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ":) -> 0.816147\n",
            ":( -> 0.115773\n",
            "I am happy -> 0.518581\n",
            "This course is great -> 0.515933\n",
            "I do not expect so much from my soccer team -> 0.494500\n",
            "It was a good book -> 0.513107\n",
            "I am not sure about the text -> 0.501005\n"
          ]
        }
      ],
      "source": [
        "# Vamos testar a fun√ß√£o\n",
        "for tweet in [':)',\n",
        "              ':(',\n",
        "              'I am happy',\n",
        "              'This course is great',\n",
        "              'I do not expect so much from my soccer team',\n",
        "              'It was a good book',\n",
        "              'I am not sure about the text']:\n",
        "    print( '%s -> %f' % (tweet, func_previsao(tweet, freqs, pesos)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03526ebe",
      "metadata": {
        "id": "03526ebe"
      },
      "source": [
        "## Avalia√ß√£o do Modelo\n",
        "\n",
        "Vamos agora avaliar a performance do modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0db1b67d",
      "metadata": {
        "id": "0db1b67d"
      },
      "source": [
        "Vamos criar uma fun√ß√£o para testar o modelo que executar√° as seguintes tarefas:\n",
        "\n",
        "* Recebe os dados de teste e os pesos do modelo treinado e calcula a precis√£o do modelo.\n",
        "* Usa a fun√ß√£o `func_previsao` para fazer previs√µes sobre cada tweet no conjunto de teste.\n",
        "* Se a previs√£o for > 0,5, definimos a classifica√ß√£o do modelo 'y_hat' como 1, caso contr√°rio, definimos a classifica√ß√£o do modelo `y_pred` como 0.\n",
        "* Uma previs√£o √© precisa quando o `y_pred` √© igual ao `y_teste`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d225c2bd",
      "metadata": {
        "id": "d225c2bd"
      },
      "outputs": [],
      "source": [
        "# Fun√ß√£o para testar o modelo\n",
        "def func_testa_modelo(test_x, test_y, freqs, theta):\n",
        "\n",
        "    # Lista para s previs√µes\n",
        "    y_hat = []\n",
        "\n",
        "    # Loop pelos dados\n",
        "    for tweet in test_x:\n",
        "\n",
        "        # Faz a previs√£o\n",
        "        y_pred = func_previsao(tweet, freqs, theta)\n",
        "\n",
        "        # Cutoff\n",
        "        if y_pred > 0.5:\n",
        "            y_hat.append(1)\n",
        "        else:\n",
        "            # append 0 to the list\n",
        "            y_hat.append(0)\n",
        "\n",
        "    # Calcula a acur√°cia\n",
        "    accuracy = (y_hat==np.squeeze(test_y)).sum() / len(test_x)\n",
        "\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "951cd5a6",
      "metadata": {
        "id": "951cd5a6"
      },
      "outputs": [],
      "source": [
        "acuracia = func_testa_modelo(dados_teste_x, y_teste, freqs, pesos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "425f10dc",
      "metadata": {
        "id": "425f10dc",
        "outputId": "94edbe3e-e878-4549-8651-017aeb653710",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acur√°cia do Modelo = 0.9950\n"
          ]
        }
      ],
      "source": [
        "print(f\"Acur√°cia do Modelo = {acuracia:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4985bd6b",
      "metadata": {
        "id": "4985bd6b"
      },
      "source": [
        "## Deploy do Modelo Treinado e Uso com Novos Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ff7d98a",
      "metadata": {
        "id": "4ff7d98a"
      },
      "outputs": [],
      "source": [
        "# Cria um tweet\n",
        "meu_tweet_1 = 'This is a great course. I am learning a lot!'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70fe8fa7",
      "metadata": {
        "id": "70fe8fa7",
        "outputId": "00849103-f535-43f3-dd40-33f64b2793f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['great', 'cours', 'learn', 'lot']\n"
          ]
        }
      ],
      "source": [
        "print(limpa_processa_tweet(meu_tweet_1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5899cf9e",
      "metadata": {
        "id": "5899cf9e",
        "outputId": "61d1d0f8-de9e-425b-af24-af1c0446bbf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.5242686]]\n"
          ]
        }
      ],
      "source": [
        "# Previs√£o\n",
        "y_hat = func_previsao(meu_tweet_1, freqs, pesos)\n",
        "print(y_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2f10ede",
      "metadata": {
        "id": "e2f10ede",
        "outputId": "2931dd17-f790-4463-ba1a-9d7ee950ce5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O Tweet tem sentimento positivo!\n"
          ]
        }
      ],
      "source": [
        "# Cutoff\n",
        "if y_hat > 0.5:\n",
        "    print('O Tweet tem sentimento positivo!')\n",
        "else:\n",
        "    print('O Tweet tem sentimento negativo!')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inser√ß√£o manual"
      ],
      "metadata": {
        "id": "uMBd6SEMsNv3"
      },
      "id": "uMBd6SEMsNv3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria um tweet\n",
        "meu_tweet_aleatorio = input('Insira o seu tweet em ingl√™s: ')\n",
        "\n",
        "# Limpa o tweet\n",
        "print(limpa_processa_tweet(meu_tweet_aleatorio))\n",
        "\n",
        "# Previs√£o\n",
        "y_hat = func_previsao(meu_tweet_aleatorio, freqs, pesos)\n",
        "print(y_hat)\n",
        "\n",
        "# Cutoff\n",
        "if y_hat > 0.5:\n",
        "    print('O Tweet tem um sentimento positivo maior!')\n",
        "else:\n",
        "    print('O Tweet tem um sentimento negativo menor!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwnGH-SsrJTi",
        "outputId": "7eba9d78-65e3-43e4-f1f7-ede421cd4301"
      },
      "id": "pwnGH-SsrJTi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Insira o seu tweet em ingl√™s: I hate this\n",
            "['hate']\n",
            "[[0.49493327]]\n",
            "O Tweet tem um sentimento negativo menor!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}